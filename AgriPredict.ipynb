{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "16UNy1lwgEeG",
        "outputId": "d25129c2-0f9f-49ad-e65d-97979516deb0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.11/dist-packages (3.5.1)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.11/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ve3mXT50bifm"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# PySpark imports\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import *\n",
        "from pyspark.sql import functions as F\n",
        "from pyspark.sql.types import StringType\n",
        "from pyspark.sql import Window\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a1td_hv3bl7u"
      },
      "outputs": [],
      "source": [
        "spark = SparkSession.builder \\\n",
        "    .appName(\"Agriculture Data Processing\") \\\n",
        "    .getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YwCZJyTz63L7"
      },
      "outputs": [],
      "source": [
        "# Suppress warnings (equivalent to warnings.filterwarnings('ignore'))\n",
        "spark.sparkContext.setLogLevel(\"ERROR\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YJ5M3SDl66Po"
      },
      "source": [
        "-------------------------------------\n",
        "### 1. DATA LOADING AND MERGING\n",
        "-------------------------------------\n",
        "##### STEP 1: DATA LOADING AND MERGING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ubcpVqFbrtI",
        "outputId": "27dd76d6-85a8-43fd-afc2-396127284010"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    - All datasets loaded.\n",
            "    - Fertilizer shape: 1843, 6\n",
            "    - Crop yield shape: 246091, 7\n",
            "    - Rainfall shape: 180, 14\n",
            "    - Temperature shape: 33, 5\n"
          ]
        }
      ],
      "source": [
        "# Load all datasets\n",
        "fertilizer_df = spark.read.csv('Fertilizer.csv', header=True, inferSchema=True)\n",
        "crop_yield_df = spark.read.csv('crop_yield.csv', header=True, inferSchema=True)\n",
        "rainfall_df = spark.read.csv('rainfall_validation.csv', header=True, inferSchema=True)\n",
        "temperature_df = spark.read.csv('final_temperature.csv', header=True, inferSchema=True)\n",
        "\n",
        "print(\"    - All datasets loaded.\")\n",
        "\n",
        "print(f\"    - Fertilizer shape: {fertilizer_df.count()}, {len(fertilizer_df.columns)}\")\n",
        "print(f\"    - Crop yield shape: {crop_yield_df.count()}, {len(crop_yield_df.columns)}\")\n",
        "print(f\"    - Rainfall shape: {rainfall_df.count()}, {len(rainfall_df.columns)}\")\n",
        "print(f\"    - Temperature shape: {temperature_df.count()}, {len(temperature_df.columns)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i9goRu3Zb99s",
        "outputId": "0846a9c0-8eb6-4255-ef73-ecd76aaa45b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    - Text data standardized (lowercase, stripped whitespace).\n"
          ]
        }
      ],
      "source": [
        "# Standardize text data function\n",
        "def standardize_text(df, cols):\n",
        "    for col_name in cols:\n",
        "        if col_name in df.columns:\n",
        "            df = df.withColumn(col_name, F.lower(F.trim(F.col(col_name))))\n",
        "    return df\n",
        "# Apply text standardization\n",
        "crop_yield_df = standardize_text(crop_yield_df, ['State_Name', 'District_Name', 'Crop', 'Season'])\n",
        "rainfall_df = standardize_text(rainfall_df, ['SUBDIVISION'])\n",
        "temperature_df = standardize_text(temperature_df, ['States'])\n",
        "fertilizer_df = standardize_text(fertilizer_df, ['Crop'])\n",
        "\n",
        "print(\"    - Text data standardized (lowercase, stripped whitespace).\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Laeip54QcFmo",
        "outputId": "bec094c5-a9dd-431f-e595-3aef6fe46751"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    - State names mapped for consistency.\n"
          ]
        }
      ],
      "source": [
        "# State name mapping for consistency\n",
        "state_name_mapping = {\n",
        "    'andaman & nicobar islands': 'andaman and nicobar islands',\n",
        "    'dadra & nagar haveli': 'dadra and nagar haveli',\n",
        "    'jammu & kashmir': 'jammu and kashmir',\n",
        "    'n.i. karnataka': 'north interior karnataka',\n",
        "    's.i. karnataka': 'south interior karnataka',\n",
        "    'rayalaseema': 'andhra pradesh',\n",
        "    'coastal andhra pradesh': 'andhra pradesh',\n",
        "    'telangana': 'andhra pradesh',\n",
        "    'puducherry': 'pondicherry',\n",
        "    'daman & diu': 'daman and diu',\n",
        "    'uttaranchal': 'uttarakhand'\n",
        "}\n",
        "# Replace state names\n",
        "for old_name, new_name in state_name_mapping.items():\n",
        "    rainfall_df = rainfall_df.withColumn('SUBDIVISION', F.when(F.col('SUBDIVISION') == old_name, new_name).otherwise(F.col('SUBDIVISION')))\n",
        "    temperature_df = temperature_df.withColumn('States', F.when(F.col('States') == old_name, new_name).otherwise(F.col('States')))\n",
        "\n",
        "print(\"    - State names mapped for consistency.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7R9VAgtq9o8c",
        "outputId": "094e9c7c-250c-4071-f178-bfb53691437f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    - Rainfall data processed (seasonal/yearly sums calculated).\n"
          ]
        }
      ],
      "source": [
        "# Process rainfall data\n",
        "rainfall_df = rainfall_df.withColumnRenamed('SUBDIVISION', 'State_Name') \\\n",
        "    .withColumnRenamed('YEAR', 'Crop_Year') \\\n",
        "    .withColumn('kharif_rainfall', (F.col('JUN') + F.col('JUL') + F.col('AUG') + F.col('SEP'))) \\\n",
        "    .withColumn('rabi_rainfall', (F.col('OCT') + F.col('NOV') + F.col('DEC') + F.col('JAN'))) \\\n",
        "    .withColumn('summer_rainfall', (F.col('FEB') + F.col('MAR') + F.col('APR') + F.col('MAY'))) \\\n",
        "    .withColumn('yearly_rainfall', F.expr('JAN + FEB + MAR + APR + MAY + JUN + JUL + AUG + SEP + OCT + NOV + DEC'))\n",
        "\n",
        "processed_rainfall_df = rainfall_df.select('State_Name', 'Crop_Year', 'kharif_rainfall', 'rabi_rainfall', 'summer_rainfall', 'yearly_rainfall')\n",
        "\n",
        "print(\"    - Rainfall data processed (seasonal/yearly sums calculated).\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d0lxAJ-JAd1w",
        "outputId": "3e512b96-62b1-496d-e1fb-aede69057c36"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    - Shape after merging rainfall: 248760, 11\n",
            "    - Shape after merging temperature: 261057, 15\n",
            "    - Shape after merging fertilizer: 1726005, 20\n"
          ]
        }
      ],
      "source": [
        "# Merge datasets\n",
        "df_merged = crop_yield_df.join(processed_rainfall_df, on=['State_Name', 'Crop_Year'], how='left')\n",
        "print(f\"    - Shape after merging rainfall: {df_merged.count()}, {len(df_merged.columns)}\")\n",
        "\n",
        "temperature_df = temperature_df.withColumnRenamed('States', 'State_Name')\n",
        "df_merged = df_merged.join(temperature_df, on='State_Name', how='left')\n",
        "print(f\"    - Shape after merging temperature: {df_merged.count()}, {len(df_merged.columns)}\")\n",
        "\n",
        "df_merged = df_merged.join(fertilizer_df, on='Crop', how='left')\n",
        "print(f\"    - Shape after merging fertilizer: {df_merged.count()}, {len(df_merged.columns)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fmm2qZWZKItB",
        "outputId": "b1efcf0b-8ca9-4433-95ec-f0634098bb36"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------------------+--------------------+---------+-------------+------+------+----------+---------------+-------------+---------------+---------------+-----------+---------+-----------+------------------+----+----+----+----+----+\n",
            "|               Crop|          State_Name|Crop_Year|District_Name|Season|  Area|Production|kharif_rainfall|rabi_rainfall|summer_rainfall|yearly_rainfall|kharif_temp|rabi_temp|summer_temp|       yearly_temp| _c0|   N|   P|   K|  pH|\n",
            "+-------------------+--------------------+---------+-------------+------+------+----------+---------------+-------------+---------------+---------------+-----------+---------+-----------+------------------+----+----+----+----+----+\n",
            "|           arecanut|andaman and nicob...|     2000|     nicobars|kharif|1254.0|    2000.0|           NULL|         NULL|           NULL|           NULL|       27.0|     26.6|       27.8|27.036363636363635|1836| 100|  40| 140|5.82|\n",
            "|           arecanut|andaman and nicob...|     2000|     nicobars|kharif|1254.0|    2000.0|           NULL|         NULL|           NULL|           NULL|       27.0|     26.6|       27.8|27.036363636363635|1739| 100|  40| 140|5.84|\n",
            "|           arecanut|andaman and nicob...|     2000|     nicobars|kharif|1254.0|    2000.0|           NULL|         NULL|           NULL|           NULL|       27.0|     26.6|       27.8|27.036363636363635|1642| 100|  40| 140|5.86|\n",
            "|           arecanut|andaman and nicob...|     2000|     nicobars|kharif|1254.0|    2000.0|           NULL|         NULL|           NULL|           NULL|       27.0|     26.6|       27.8|27.036363636363635|1545| 100|  40| 140|5.88|\n",
            "|           arecanut|andaman and nicob...|     2000|     nicobars|kharif|1254.0|    2000.0|           NULL|         NULL|           NULL|           NULL|       27.0|     26.6|       27.8|27.036363636363635|1448| 100|  40| 140| 5.9|\n",
            "|           arecanut|andaman and nicob...|     2000|     nicobars|kharif|1254.0|    2000.0|           NULL|         NULL|           NULL|           NULL|       27.0|     26.6|       27.8|27.036363636363635|1351| 100|  40| 140|5.92|\n",
            "|           arecanut|andaman and nicob...|     2000|     nicobars|kharif|1254.0|    2000.0|           NULL|         NULL|           NULL|           NULL|       27.0|     26.6|       27.8|27.036363636363635|1254| 100|  40| 140|5.94|\n",
            "|           arecanut|andaman and nicob...|     2000|     nicobars|kharif|1254.0|    2000.0|           NULL|         NULL|           NULL|           NULL|       27.0|     26.6|       27.8|27.036363636363635|1157| 100|  40| 140|5.96|\n",
            "|           arecanut|andaman and nicob...|     2000|     nicobars|kharif|1254.0|    2000.0|           NULL|         NULL|           NULL|           NULL|       27.0|     26.6|       27.8|27.036363636363635|1060| 100|  40| 140|5.98|\n",
            "|           arecanut|andaman and nicob...|     2000|     nicobars|kharif|1254.0|    2000.0|           NULL|         NULL|           NULL|           NULL|       27.0|     26.6|       27.8|27.036363636363635| 963| 100|  40| 140|6.18|\n",
            "|           arecanut|andaman and nicob...|     2000|     nicobars|kharif|1254.0|    2000.0|           NULL|         NULL|           NULL|           NULL|       27.0|     26.6|       27.8|27.036363636363635| 866| 100|  40| 140|6.16|\n",
            "|           arecanut|andaman and nicob...|     2000|     nicobars|kharif|1254.0|    2000.0|           NULL|         NULL|           NULL|           NULL|       27.0|     26.6|       27.8|27.036363636363635| 769| 100|  40| 140|6.14|\n",
            "|           arecanut|andaman and nicob...|     2000|     nicobars|kharif|1254.0|    2000.0|           NULL|         NULL|           NULL|           NULL|       27.0|     26.6|       27.8|27.036363636363635| 672| 100|  40| 140|6.12|\n",
            "|           arecanut|andaman and nicob...|     2000|     nicobars|kharif|1254.0|    2000.0|           NULL|         NULL|           NULL|           NULL|       27.0|     26.6|       27.8|27.036363636363635| 575| 100|  40| 140| 6.1|\n",
            "|           arecanut|andaman and nicob...|     2000|     nicobars|kharif|1254.0|    2000.0|           NULL|         NULL|           NULL|           NULL|       27.0|     26.6|       27.8|27.036363636363635| 478| 100|  40| 140|6.08|\n",
            "|           arecanut|andaman and nicob...|     2000|     nicobars|kharif|1254.0|    2000.0|           NULL|         NULL|           NULL|           NULL|       27.0|     26.6|       27.8|27.036363636363635| 381| 100|  40| 140|6.06|\n",
            "|           arecanut|andaman and nicob...|     2000|     nicobars|kharif|1254.0|    2000.0|           NULL|         NULL|           NULL|           NULL|       27.0|     26.6|       27.8|27.036363636363635| 284| 100|  40| 140|6.04|\n",
            "|           arecanut|andaman and nicob...|     2000|     nicobars|kharif|1254.0|    2000.0|           NULL|         NULL|           NULL|           NULL|       27.0|     26.6|       27.8|27.036363636363635| 187| 100|  40| 140|6.02|\n",
            "|           arecanut|andaman and nicob...|     2000|     nicobars|kharif|1254.0|    2000.0|           NULL|         NULL|           NULL|           NULL|       27.0|     26.6|       27.8|27.036363636363635|  90| 100|  40| 140| 6.0|\n",
            "|other kharif pulses|andaman and nicob...|     2000|     nicobars|kharif|   2.0|       1.0|           NULL|         NULL|           NULL|           NULL|       27.0|     26.6|       27.8|27.036363636363635|NULL|NULL|NULL|NULL|NULL|\n",
            "+-------------------+--------------------+---------+-------------+------+------+----------+---------------+-------------+---------------+---------------+-----------+---------+-----------+------------------+----+----+----+----+----+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df_merged.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u53hNUleB4Ac"
      },
      "source": [
        "-------------------------------------\n",
        "### 2. DATA QUALITY CHECKS AND CLEANING\n",
        "-------------------------------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QonpO_wzBPWy",
        "outputId": "eadf0eb5-945a-4b47-89fd-25244ab615e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Missing values before cleaning:\n",
            "+----+----------+---------+-------------+------+----+----------+---------------+-------------+---------------+---------------+-----------+---------+-----------+-----------+------+------+------+------+------+\n",
            "|Crop|State_Name|Crop_Year|District_Name|Season|Area|Production|kharif_rainfall|rabi_rainfall|summer_rainfall|yearly_rainfall|kharif_temp|rabi_temp|summer_temp|yearly_temp|   _c0|     N|     P|     K|    pH|\n",
            "+----+----------+---------+-------------+------+----+----------+---------------+-------------+---------------+---------------+-----------+---------+-----------+-----------+------+------+------+------+------+\n",
            "|   0|         0|        0|            0|     0|   0|     18677|        1552997|      1552997|        1552997|        1552997|      41031|    41031|      41031|      41031|179671|179671|179671|179671|179671|\n",
            "+----+----------+---------+-------------+------+----+----------+---------------+-------------+---------------+---------------+-----------+---------+-----------+-----------+------+------+------+------+------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Check for missing values\n",
        "print(\"\\nMissing values before cleaning:\")\n",
        "missing_values = df_merged.select([F.count(F.when(F.col(c).isNull(), c)).alias(c) for c in df_merged.columns])\n",
        "missing_values.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DP0_XGU_m8Kl"
      },
      "outputs": [],
      "source": [
        "# Handle missing values\n",
        "# For numerical columns, fill with grouped means\n",
        "numerical_cols = ['Area', 'Production', 'kharif_rainfall', 'rabi_rainfall',\n",
        "                  'summer_rainfall', 'yearly_rainfall', 'kharif_temp',\n",
        "                  'rabi_temp', 'summer_temp', 'yearly_temp', 'N', 'P', 'K', 'pH']\n",
        "\n",
        "for col_name in numerical_cols:\n",
        "    if col_name in df_merged.columns:\n",
        "        if 'rainfall' in col_name:\n",
        "            group_cols = ['State_Name', 'Crop_Year']\n",
        "        elif 'temp' in col_name:\n",
        "            group_cols = ['State_Name']\n",
        "        elif col_name in ['N', 'P', 'K', 'pH']:\n",
        "            group_cols = ['Crop']\n",
        "        else:\n",
        "            group_cols = ['State_Name', 'Crop', 'Season']\n",
        "\n",
        "        df_merged = df_merged.withColumn(col_name, F.when(F.col(col_name).isNull(),\n",
        "            F.mean(col_name).over(Window.partitionBy(*group_cols))).otherwise(F.col(col_name)))\n",
        "\n",
        "        # Fill remaining with global mean\n",
        "        global_mean = df_merged.select(F.mean(col_name)).first()[0]\n",
        "        df_merged = df_merged.withColumn(col_name, F.when(F.col(col_name).isNull(), global_mean).otherwise(F.col(col_name)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bytWihRjFEUD",
        "outputId": "08e37042-5eab-41fe-f016-4dc029038515"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    - Missing values handled for categorical columns.\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql import functions as F\n",
        "\n",
        "# For categorical columns, fill with mode or 'unknown'\n",
        "categorical_cols = ['State_Name', 'District_Name', 'Crop', 'Season']\n",
        "for col_name in categorical_cols:\n",
        "    if col_name in df_merged.columns:\n",
        "        # Calculate mode\n",
        "        mode_value = df_merged.select(col_name).na.drop().agg(F.mode(col_name)).first()[0]\n",
        "\n",
        "        # Fill missing values with mode or 'unknown' if mode is None\n",
        "        df_merged = df_merged.withColumn(col_name,\n",
        "                                          F.when(F.col(col_name).isNull(), mode_value if mode_value is not None else 'unknown')\n",
        "                                          .otherwise(F.col(col_name)))\n",
        "\n",
        "print(\"    - Missing values handled for categorical columns.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CzbXkYMahWeT",
        "outputId": "ea28f494-1b70-4a74-853f-c0a12902f7a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Missing values after cleaning:\n",
            "+----+----------+---------+-------------+------+----+----------+---------------+-------------+---------------+---------------+-----------+---------+-----------+-----------+------+---+---+---+---+\n",
            "|Crop|State_Name|Crop_Year|District_Name|Season|Area|Production|kharif_rainfall|rabi_rainfall|summer_rainfall|yearly_rainfall|kharif_temp|rabi_temp|summer_temp|yearly_temp|   _c0|  N|  P|  K| pH|\n",
            "+----+----------+---------+-------------+------+----+----------+---------------+-------------+---------------+---------------+-----------+---------+-----------+-----------+------+---+---+---+---+\n",
            "|   0|         0|        0|            0|     0|   0|         0|              0|            0|              0|              0|          0|        0|          0|          0|179671|  0|  0|  0|  0|\n",
            "+----+----------+---------+-------------+------+----+----------+---------------+-------------+---------------+---------------+-----------+---------+-----------+-----------+------+---+---+---+---+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nMissing values after cleaning:\")\n",
        "missing_values_after = df_merged.select([F.count(F.when(F.col(c).isNull(), c)).alias(c) for c in df_merged.columns])\n",
        "missing_values_after.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4PZm8pN2TLbZ",
        "outputId": "eb718397-fd96-4f8b-ed94-18e83ee2686a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    - Column '_c0' dropped from the DataFrame.\n"
          ]
        }
      ],
      "source": [
        "# Drop the _c0 column from the DataFrame\n",
        "df_merged = df_merged.drop('_c0')\n",
        "print(\"    - Column '_c0' dropped from the DataFrame.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "msNpb9VYA2s2",
        "outputId": "f15581a4-6c2a-48c6-8efa-d44eff999a53"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- Crop: string (nullable = true)\n",
            " |-- State_Name: string (nullable = true)\n",
            " |-- Crop_Year: integer (nullable = true)\n",
            " |-- District_Name: string (nullable = true)\n",
            " |-- Season: string (nullable = true)\n",
            " |-- Area: double (nullable = true)\n",
            " |-- Production: double (nullable = true)\n",
            " |-- kharif_rainfall: double (nullable = true)\n",
            " |-- rabi_rainfall: double (nullable = true)\n",
            " |-- summer_rainfall: double (nullable = true)\n",
            " |-- yearly_rainfall: double (nullable = true)\n",
            " |-- kharif_temp: double (nullable = true)\n",
            " |-- rabi_temp: double (nullable = true)\n",
            " |-- summer_temp: double (nullable = true)\n",
            " |-- yearly_temp: double (nullable = true)\n",
            " |-- N: double (nullable = true)\n",
            " |-- P: double (nullable = true)\n",
            " |-- K: double (nullable = true)\n",
            " |-- pH: double (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df_merged.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z9p24CwgN2-V",
        "outputId": "4ae8daa2-9e23-4572-b084-308ab7e4027c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Number of duplicates after cleaning: 0\n"
          ]
        }
      ],
      "source": [
        "# Remove duplicates if any\n",
        "df_merged = df_merged.dropDuplicates()\n",
        "print(f\"\\nNumber of duplicates after cleaning: {df_merged.count() - df_merged.distinct().count()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YXJG9giqGn51",
        "outputId": "d2c43615-1e71-4ebb-b5cf-ace84b6fbc20"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---------+--------------+---------+---------------+------+-------+----------+-----------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+-----------------+-----------------+------------------+------------------+\n",
            "|     Crop|    State_Name|Crop_Year|  District_Name|Season|   Area|Production|  kharif_rainfall|     rabi_rainfall|   summer_rainfall|   yearly_rainfall|       kharif_temp|         rabi_temp|       summer_temp|       yearly_temp|                N|                P|                 K|                pH|\n",
            "+---------+--------------+---------+---------------+------+-------+----------+-----------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+-----------------+-----------------+------------------+------------------+\n",
            "|arhar/tur|andhra pradesh|     2001|     srikakulam|kharif| 1395.0|     813.0|893.3752340934094| 206.7744312402807|133.81339360030313|1233.9630589330843| 29.26666666666667|             25.46|31.266666666666666|28.081818181818186|82.97870641142211|45.61761236576315|53.883284594401985|5.4882731673752145|\n",
            "|arhar/tur|andhra pradesh|     2009|         kadapa|kharif|12353.0|    2088.0|893.3752340934094| 206.7744312402807|133.81339360030313|1233.9630589330843|28.679999999999996|            25.574|             35.01|28.994545454545456|82.97870641142211|45.61761236576315|53.883284594401985|5.4882731673752145|\n",
            "|arhar/tur|andhra pradesh|     2011| visakhapatanam|kharif| 2719.0|    1088.0|            628.3|              84.5|             149.0|             861.8| 29.26666666666667|             25.46|31.266666666666666|28.081818181818186|82.97870641142211|45.61761236576315|53.883284594401985|5.4882731673752145|\n",
            "|arhar/tur|andhra pradesh|     1998|        kurnool|kharif|26400.0|   10000.0|893.3752340934094| 206.7744312402807|133.81339360030313|1233.9630589330843|28.679999999999996|            25.574|             35.01|28.994545454545456|82.97870641142211|45.61761236576315|53.883284594401985|5.4882731673752145|\n",
            "|arhar/tur|andhra pradesh|     2013|  east godavari|kharif|  465.0|     447.0|            545.0|469.40000000000003|             106.0|1120.3999999999999|28.679999999999996|            25.574|             35.01|28.994545454545456|82.97870641142211|45.61761236576315|53.883284594401985|5.4882731673752145|\n",
            "|arhar/tur|         bihar|     2006|          saran|kharif| 1479.0|    1781.0|893.3752340934094| 206.7744312402807|133.81339360030313|1233.9630589330843|33.583333333333336|            23.106| 34.92333333333334|29.186363636363637|82.97870641142211|45.61761236576315|53.883284594401985|5.4882731673752145|\n",
            "|arhar/tur|         bihar|     1998|        sheohar|kharif|  317.0|     559.0|893.3752340934094| 206.7744312402807|133.81339360030313|1233.9630589330843|33.583333333333336|            23.106| 34.92333333333334|29.186363636363637|82.97870641142211|45.61761236576315|53.883284594401985|5.4882731673752145|\n",
            "|arhar/tur|     karnataka|     2004|         koppal|kharif|11807.0|    2490.0|893.3752340934094| 206.7744312402807|133.81339360030313|1233.9630589330843|22.599999999999998|              21.3|25.833333333333332| 22.89090909090909|82.97870641142211|45.61761236576315|53.883284594401985|5.4882731673752145|\n",
            "|arhar/tur|   maharashtra|     2004|         nashik|kharif| 9200.0|    6500.0|893.3752340934094| 206.7744312402807|133.81339360030313|1233.9630589330843|26.366666666666664|              25.6| 27.96666666666667|26.454545454545453|82.97870641142211|45.61761236576315|53.883284594401985|5.4882731673752145|\n",
            "|arhar/tur|   maharashtra|     1997|       kolhapur|kharif| 3700.0|     900.0|893.3752340934094| 206.7744312402807|133.81339360030313|1233.9630589330843|26.366666666666664|              25.6| 27.96666666666667|26.454545454545453|82.97870641142211|45.61761236576315|53.883284594401985|5.4882731673752145|\n",
            "|arhar/tur|   maharashtra|     2005|         wardha|kharif|52400.0|   53100.0|893.3752340934094| 206.7744312402807|133.81339360030313|1233.9630589330843|26.366666666666664|              25.6| 27.96666666666667|26.454545454545453|82.97870641142211|45.61761236576315|53.883284594401985|5.4882731673752145|\n",
            "|arhar/tur|   maharashtra|     2006|       kolhapur|kharif| 2800.0|    1400.0|893.3752340934094| 206.7744312402807|133.81339360030313|1233.9630589330843|26.366666666666664|              25.6| 27.96666666666667|26.454545454545453|82.97870641142211|45.61761236576315|53.883284594401985|5.4882731673752145|\n",
            "|arhar/tur|     meghalaya|     2014|east garo hills|kharif|   71.0|      69.0|893.3752340934094| 206.7744312402807|133.81339360030313|1233.9630589330843|22.070000000000004|15.851999999999999|20.363333333333333|18.778181818181817|82.97870641142211|45.61761236576315|53.883284594401985|5.4882731673752145|\n",
            "|arhar/tur|      nagaland|     2003|       tuensang|kharif|  810.0|     780.0|893.3752340934094| 206.7744312402807|133.81339360030313|1233.9630589330843|26.433333333333334|             18.92|23.400000000000002| 22.19090909090909|82.97870641142211|45.61761236576315|53.883284594401985|5.4882731673752145|\n",
            "|arhar/tur|      nagaland|     2005|      zunheboto|kharif|  760.0|     500.0|893.3752340934094| 206.7744312402807|133.81339360030313|1233.9630589330843|26.433333333333334|             18.92|23.400000000000002| 22.19090909090909|82.97870641142211|45.61761236576315|53.883284594401985|5.4882731673752145|\n",
            "|arhar/tur|      nagaland|     2014|          wokha|kharif|  190.0|     170.0|893.3752340934094| 206.7744312402807|133.81339360030313|1233.9630589330843|26.433333333333334|             18.92|23.400000000000002| 22.19090909090909|82.97870641142211|45.61761236576315|53.883284594401985|5.4882731673752145|\n",
            "|arhar/tur|        odisha|     1997|       balangir|autumn| 4768.0|    1117.0|893.3752340934094| 206.7744312402807|133.81339360030313|1233.9630589330843|              28.5|             23.56|30.266666666666666|26.736363636363635|82.97870641142211|45.61761236576315|53.883284594401985|5.4882731673752145|\n",
            "|arhar/tur|        odisha|     1997|      dhenkanal|summer|  904.0|     203.0|893.3752340934094| 206.7744312402807|133.81339360030313|1233.9630589330843|              28.5|             23.56|30.266666666666666|26.736363636363635|82.97870641142211|45.61761236576315|53.883284594401985|5.4882731673752145|\n",
            "|arhar/tur|        odisha|     2002|        bhadrak|kharif|   30.0|      30.0|893.3752340934094| 206.7744312402807|133.81339360030313|1233.9630589330843|              28.5|             23.56|30.266666666666666|26.736363636363635|82.97870641142211|45.61761236576315|53.883284594401985|5.4882731673752145|\n",
            "|arhar/tur|        odisha|     2003|     jharsuguda|kharif|  580.0|     370.0|893.3752340934094| 206.7744312402807|133.81339360030313|1233.9630589330843|              28.5|             23.56|30.266666666666666|26.736363636363635|82.97870641142211|45.61761236576315|53.883284594401985|5.4882731673752145|\n",
            "+---------+--------------+---------+---------------+------+-------+----------+-----------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+-----------------+-----------------+------------------+------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df_merged.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_TFUuPkoGkYz",
        "outputId": "ccd011f4-1759-487c-a3d9-e3c4d166ee2a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    - Intermediate merged data saved.\n"
          ]
        }
      ],
      "source": [
        "# Save intermediate merged data\n",
        "df_initial_merged = df_merged\n",
        "\n",
        "df_initial_merged.toPandas().to_csv('agripredict_initial_merged_data.csv', index=False)\n",
        "print(\"    - Intermediate merged data saved.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7rohfs2tOEep"
      },
      "source": [
        "-------------------------------------\n",
        "### 3. FEATURE ENGINEERING\n",
        "-------------------------------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CyVRrqkEOBY7",
        "outputId": "388e9d84-575e-44e9-cf9a-69afde1e2a2c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    - Created 'relevant_rainfall' and 'relevant_temperature' features.\n"
          ]
        }
      ],
      "source": [
        "# Create relevant rainfall and temperature based on season\n",
        "conditions = [\n",
        "    df_merged['Season'].contains('kharif'),\n",
        "    df_merged['Season'].contains('rabi'),\n",
        "    df_merged['Season'].contains('summer') | df_merged['Season'].contains('zaid'),\n",
        "    df_merged['Season'].contains('whole year')\n",
        "]\n",
        "\n",
        "choices = [\n",
        "    df_merged['kharif_rainfall'],\n",
        "    df_merged['rabi_rainfall'],\n",
        "    df_merged['summer_rainfall'],\n",
        "    df_merged['yearly_rainfall']\n",
        "]\n",
        "\n",
        "df_merged = df_merged.withColumn('relevant_rainfall', F.when(conditions[0], choices[0])\n",
        "                                  .when(conditions[1], choices[1])\n",
        "                                  .when(conditions[2], choices[2])\n",
        "                                  .when(conditions[3], choices[3])\n",
        "                                  .otherwise(None))\n",
        "\n",
        "conditions_temp = [\n",
        "    df_merged['Season'].contains('kharif'),\n",
        "    df_merged['Season'].contains('rabi'),\n",
        "    df_merged['Season'].contains('summer') | df_merged['Season'].contains('zaid'),\n",
        "    df_merged['Season'].contains('whole year')\n",
        "]\n",
        "\n",
        "choices_temp = [\n",
        "    df_merged['kharif_temp'],\n",
        "    df_merged['rabi_temp'],\n",
        "    df_merged['summer_temp'],\n",
        "    df_merged['yearly_temp']\n",
        "]\n",
        "\n",
        "df_merged = df_merged.withColumn('relevant_temperature', F.when(conditions_temp[0], choices_temp[0])\n",
        "                                  .when(conditions_temp[1], choices_temp[1])\n",
        "                                  .when(conditions_temp[2], choices_temp[2])\n",
        "                                  .when(conditions_temp[3], choices_temp[3])\n",
        "                                  .otherwise(None))\n",
        "\n",
        "print(\"    - Created 'relevant_rainfall' and 'relevant_temperature' features.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ju3uH2aMOBVZ"
      },
      "outputs": [],
      "source": [
        "# Calculate yield (production/area)\n",
        "df_merged = df_merged.withColumn('Area', F.when(F.col('Area') == 0, None).otherwise(F.col('Area')))\n",
        "df_merged = df_merged.withColumn('Yield_ton_per_hec', F.col('Production') / F.col('Area'))\n",
        "df_merged = df_merged.withColumn('Yield_ton_per_hec', F.when(F.col('Yield_ton_per_hec').isNull(), None).otherwise(F.col('Yield_ton_per_hec')))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ShOr01CkOBS1",
        "outputId": "a6bd38ee-e363-4c93-d608-c9cd770bc465"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    - Calculated 'Yield_ton_per_hec'.\n"
          ]
        }
      ],
      "source": [
        "# Fill yield NaNs with crop-season averages\n",
        "df_merged = df_merged.withColumn('Yield_ton_per_hec', F.when(F.col('Yield_ton_per_hec').isNull(),\n",
        "    F.mean('Yield_ton_per_hec').over(Window.partitionBy('Crop', 'Season'))).otherwise(F.col('Yield_ton_per_hec')))\n",
        "\n",
        "# Fill remaining with global mean\n",
        "global_yield_mean = df_merged.agg(F.mean('Yield_ton_per_hec')).first()[0]\n",
        "df_merged = df_merged.withColumn('Yield_ton_per_hec', F.when(F.col('Yield_ton_per_hec').isNull(), global_yield_mean).otherwise(F.col('Yield_ton_per_hec')))\n",
        "\n",
        "print(\"    - Calculated 'Yield_ton_per_hec'.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YwL1_0RQOBQV",
        "outputId": "58b076b0-8abe-4915-d25b-c428271ee0ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    - Created interaction features.\n"
          ]
        }
      ],
      "source": [
        "# Create interaction features\n",
        "df_merged = df_merged.withColumn('rainfall_temp_interaction', F.col('relevant_rainfall') * F.col('relevant_temperature'))\n",
        "df_merged = df_merged.withColumn('NPK_ratio', F.col('N') / (F.col('P') + F.col('K') + 1e-6))\n",
        "\n",
        "print(\"    - Created interaction features.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6c6CWp34OBNk"
      },
      "outputs": [],
      "source": [
        "# Create lag features\n",
        "df_merged = df_merged.sort(['State_Name', 'District_Name', 'Crop', 'Season', 'Crop_Year'])\n",
        "df_merged = df_merged.withColumn('lagged_production_1yr',\n",
        "                                  F.lag('Production', 1).over(Window.partitionBy('State_Name', 'District_Name', 'Crop', 'Season').orderBy('Crop_Year')))\n",
        "df_merged = df_merged.withColumn('lagged_yield_1yr',\n",
        "                                  F.lag('Yield_ton_per_hec', 1).over(Window.partitionBy('State_Name', 'District_Name', 'Crop', 'Season').orderBy('Crop_Year')))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kDW9X5ElOA-9"
      },
      "outputs": [],
      "source": [
        "# Fill lag features with mean values\n",
        "df_merged = df_merged.withColumn('lagged_production_1yr', F.when(F.col('lagged_production_1yr').isNull(),\n",
        "    F.mean('lagged_production_1yr').over(Window.partitionBy('Crop', 'Season'))).otherwise(F.col('lagged_production_1yr')))\n",
        "df_merged = df_merged.withColumn('lagged_yield_1yr', F.when(F.col('lagged_yield_1yr').isNull(),\n",
        "    F.mean('lagged_yield_1yr').over(Window.partitionBy('Crop', 'Season'))).otherwise(F.col('lagged_yield_1yr')))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5SVylV6Hd97C",
        "outputId": "e9215506-7ac3-4043-fcf2-4ee7c03007d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    - Created lag features.\n"
          ]
        }
      ],
      "source": [
        "print(\"    - Created lag features.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JzBAfsHTeAi-"
      },
      "source": [
        "-----------------------------------------\n",
        "### 4. OUTLIER DETECTION AND TREATMENT\n",
        "-----------------------------------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RgwOedM3eFtf"
      },
      "outputs": [],
      "source": [
        "numerical_cols = [\n",
        "    'Area', 'Production', 'kharif_rainfall', 'rabi_rainfall',\n",
        "    'summer_rainfall', 'yearly_rainfall', 'kharif_temp',\n",
        "    'rabi_temp', 'summer_temp', 'yearly_temp', 'N', 'P', 'K',\n",
        "    'pH', 'Yield_ton_per_hec', 'rainfall_temp_interaction',\n",
        "    'NPK_ratio', 'lagged_production_1yr', 'lagged_yield_1yr'\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TBsO8fOjRdcA",
        "outputId": "1082fea3-fe48-405c-9a27-e20d4d36c0b5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    - Calculating IQR bounds for all columns...\n"
          ]
        }
      ],
      "source": [
        "# --- Step 1: Calculate Outlier Bounds Efficiently ---\n",
        "# This step still requires one approxQuantile action per column but is necessary.\n",
        "outlier_bounds = {}\n",
        "print(\"    - Calculating IQR bounds for all columns...\")\n",
        "for col_name in numerical_cols:\n",
        "    if col_name in df_merged.columns:\n",
        "        quantiles = df_merged.approxQuantile(col_name, [0.25, 0.75], 0.01)\n",
        "        if quantiles and quantiles[0] is not None and quantiles[1] is not None:\n",
        "            Q1, Q3 = quantiles[0], quantiles[1]\n",
        "            IQR = Q3 - Q1\n",
        "            lower_bound = Q1 - 1.5 * IQR\n",
        "            upper_bound = Q3 + 1.5 * IQR\n",
        "            outlier_bounds[col_name] = {'lower_bound': lower_bound, 'upper_bound': upper_bound}\n",
        "        else:\n",
        "            print(f\"        - Skipping {col_name} due to insufficient data or nulls.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "39mMZPcuR5dc",
        "outputId": "36f216f8-c0a6-4cf4-fd37-1c3bb8263542"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    - Performing Outlier Treatment (Capping) on all columns...\n",
            "    - Capping logic defined for all columns. No Spark job executed yet.\n"
          ]
        }
      ],
      "source": [
        "# --- Step 2: Create a capped DataFrame (a series of lazy transformations) ---\n",
        "print(\"    - Performing Outlier Treatment (Capping) on all columns...\")\n",
        "df_capped = df_merged\n",
        "for col_name in outlier_bounds:\n",
        "    lower_bound = outlier_bounds[col_name]['lower_bound']\n",
        "    upper_bound = outlier_bounds[col_name]['upper_bound']\n",
        "    df_capped = df_capped.withColumn(\n",
        "        col_name,\n",
        "        F.when(F.col(col_name) < lower_bound, lower_bound)\n",
        "         .when(F.col(col_name) > upper_bound, upper_bound)\n",
        "         .otherwise(F.col(col_name))\n",
        "    )\n",
        "print(\"    - Capping logic defined for all columns\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        },
        "id": "80yvLJSqR-4S",
        "outputId": "67c68e11-a6b6-4a41-d5d5-68edf553fab9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "### Generating side-by-side plots and verifying capping... ###\n",
            "---------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'df_merged' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2823013759.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n### Generating side-by-side plots and verifying capping... ###\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"---------------------------------------------------------------\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtotal_rows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_merged\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcol_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnumerical_cols\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'df_merged' is not defined"
          ]
        }
      ],
      "source": [
        "# --- Step 3: Visualize and Verify in a single loop ---\n",
        "print(\"\\n### Generating side-by-side plots and verifying capping... ###\")\n",
        "print(\"---------------------------------------------------------------\")\n",
        "total_rows = df_merged.count()\n",
        "\n",
        "for col_name in numerical_cols:\n",
        "    if col_name in outlier_bounds:\n",
        "        lower_bound = outlier_bounds[col_name]['lower_bound']\n",
        "        upper_bound = outlier_bounds[col_name]['upper_bound']\n",
        "\n",
        "        print(f\"\\n--- Analyzing and Visualizing '{col_name}' ---\")\n",
        "\n",
        "        # --- Sub-step 3.1: Efficiently count outliers before and after ---\n",
        "        outliers_low_before, outliers_high_before = df_merged.agg(\n",
        "            F.sum(F.when(F.col(col_name) < lower_bound, 1).otherwise(0)).alias('low'),\n",
        "            F.sum(F.when(F.col(col_name) > upper_bound, 1).otherwise(0)).alias('high')\n",
        "        ).collect()[0]\n",
        "\n",
        "        # We can't use the same bounds to check after capping, as new outliers may form.\n",
        "        # So we calculate new bounds for the capped data for a more accurate report.\n",
        "        quantiles_after = df_capped.approxQuantile(col_name, [0.25, 0.75], 0.01)\n",
        "        if quantiles_after:\n",
        "            Q1_after, Q3_after = quantiles_after[0], quantiles_after[1]\n",
        "            IQR_after = Q3_after - Q1_after\n",
        "            lower_bound_after = Q1_after - 1.5 * IQR_after\n",
        "            upper_bound_after = Q3_after + 1.5 * IQR_after\n",
        "            outliers_low_after, outliers_high_after = df_capped.agg(\n",
        "                F.sum(F.when(F.col(col_name) < lower_bound_after, 1).otherwise(0)).alias('low'),\n",
        "                F.sum(F.when(F.col(col_name) > upper_bound_after, 1).otherwise(0)).alias('high')\n",
        "            ).collect()[0]\n",
        "\n",
        "            print(f\"  - Before Capping: {outliers_low_before + outliers_high_before} outliers ({(outliers_low_before + outliers_high_before) / total_rows * 100:.2f}%)\")\n",
        "            print(f\"  - After Capping: {outliers_low_after + outliers_high_after} outliers ({(outliers_low_after + outliers_high_after) / total_rows * 100:.2f}%)\")\n",
        "\n",
        "        # --- Sub-step 3.2: Sample and Plot ---\n",
        "        # Sample data from both DataFrames to ensure consistent plotting\n",
        "        sample_size = 0.05  # Adjust sampling size as needed\n",
        "        sample_df_before = df_merged.select(col_name).sample(False, sample_size, seed=42).toPandas()\n",
        "        sample_df_after = df_capped.select(col_name).sample(False, sample_size, seed=42).toPandas()\n",
        "\n",
        "        if not sample_df_before.empty and not sample_df_after.empty:\n",
        "            plt.figure(figsize=(10, 6))\n",
        "\n",
        "            # Before Capping Plot\n",
        "            ax1 = plt.subplot(1, 2, 1)\n",
        "            sns.boxplot(y=sample_df_before[col_name], ax=ax1)\n",
        "            ax1.set_title(f'Box Plot of {col_name} (Before Capping)')\n",
        "            ax1.set_ylabel(col_name)\n",
        "\n",
        "            # After Capping Plot\n",
        "            ax2 = plt.subplot(1, 2, 2)\n",
        "            sns.boxplot(y=sample_df_after[col_name], ax=ax2)\n",
        "            ax2.set_title(f'Box Plot of {col_name} (After Capping)')\n",
        "            ax2.set_ylabel(col_name)\n",
        "\n",
        "            plt.tight_layout()\n",
        "            plt.show()\n",
        "            plt.close()\n",
        "        else:\n",
        "            print(f\"    - Skipping box plot for '{col_name}' (not enough sample data).\")\n",
        "    else:\n",
        "        print(f\"\\n--- Skipping '{col_name}': Not found or all values are null. ---\")\n",
        "\n",
        "# The final df_merged_spark now holds the capped values.\n",
        "df_merged_spark = df_capped\n",
        "print(\"\\n=== Outlier Detection & Treatment with Visualizations Complete. ===\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XUKj9DE2fbfv"
      },
      "source": [
        "-----------------------------------------\n",
        "### 5. EXPLORATORY DATA ANALYSIS (EDA)\n",
        "-----------------------------------------\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3jumG853fdgH"
      },
      "source": [
        "##### STEP 5: EXPLORATORY DATA ANALYSIS (EDA)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3VfebUqsfDoD"
      },
      "outputs": [],
      "source": [
        "# 1. Distribution of numerical variables\n",
        "numerical_cols_for_eda = ['Area', 'Production', 'kharif_rainfall', 'rabi_rainfall',\n",
        "                         'summer_rainfall', 'yearly_rainfall', 'kharif_temp',\n",
        "                         'rabi_temp', 'summer_temp', 'yearly_temp', 'N', 'P', 'K',\n",
        "                         'pH', 'Yield_ton_per_hec', 'rainfall_temp_interaction',\n",
        "                         'NPK_ratio']\n",
        "\n",
        "print(\"\\n1. Distribution of Numerical Variables:\")\n",
        "for col_name in numerical_cols_for_eda:\n",
        "    if col_name in df_merged.columns:\n",
        "        plt.figure(figsize=(8, 4))\n",
        "        sns.histplot(df_merged.select(col_name).toPandas()[col_name], kde=True, bins=50)\n",
        "        plt.title(f'Distribution of {col_name}')\n",
        "        plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1grTLFXqfj0E"
      },
      "outputs": [],
      "source": [
        "# 2. Categorical variable distributions\n",
        "print(\"\\n2. Distribution of Categorical Variables:\")\n",
        "categorical_cols_for_eda = ['State_Name', 'District_Name', 'Crop', 'Season']\n",
        "for col_name in categorical_cols_for_eda:\n",
        "    if col_name in df_merged.columns:\n",
        "        plt.figure(figsize=(8, 4))\n",
        "        if df_merged.select(col_name).distinct().count() > 10:  # For columns with many categories\n",
        "            top_categories = df_merged.groupBy(col_name).count().orderBy('count', ascending=False).limit(10).toPandas()[col_name]\n",
        "            sns.countplot(y=col_name, data=df_merged.toPandas(), order=top_categories)\n",
        "        else:\n",
        "            sns.countplot(x=col_name, data=df_merged.toPandas())\n",
        "        plt.title(f'Distribution of {col_name}')\n",
        "        plt.xticks(rotation=45)\n",
        "        plt.tight_layout()\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tIigc8ktfoXa"
      },
      "outputs": [],
      "source": [
        "# 3. Correlation analysis\n",
        "print(\"\\n3. Correlation Analysis:\")\n",
        "plt.figure(figsize=(10, 6))\n",
        "corr_matrix = df_merged.select(numerical_cols_for_eda).toPandas().corr()\n",
        "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=.5)\n",
        "plt.title('Correlation Matrix of Numerical Variables')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AvXAhxISfulz"
      },
      "outputs": [],
      "source": [
        "# 4. Time series analysis of yield and production\n",
        "print(\"\\n4. Time Series Analysis:\")\n",
        "if 'Crop_Year' in df_merged.columns:\n",
        "    yearly_summary = df_merged.groupBy('Crop_Year').agg(\n",
        "        spark_sum('Production').alias('Total_Production'),\n",
        "        spark_mean('Yield_ton_per_hec').alias('Average_Yield')\n",
        "    ).toPandas()\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    sns.lineplot(x='Crop_Year', y='Total_Production', data=yearly_summary, marker='o')\n",
        "    plt.title('Total Production Over Years')\n",
        "    plt.xlabel('Year')\n",
        "    plt.ylabel('Total Production')\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    sns.lineplot(x='Crop_Year', y='Average_Yield', data=yearly_summary, marker='o', color='green')\n",
        "    plt.title('Average Yield Over Years')\n",
        "    plt.xlabel('Year')\n",
        "    plt.ylabel('Average Yield (ton/hec)')\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fEaam2FgfsA9"
      },
      "outputs": [],
      "source": [
        "# 5. Relationship between key features and yield\n",
        "print(\"\\n5. Feature-Yield Relationships:\")\n",
        "key_features = ['relevant_rainfall', 'relevant_temperature', 'N', 'P', 'K', 'pH']\n",
        "for feature in key_features:\n",
        "    if feature in df_merged.columns:\n",
        "        plt.figure(figsize=(8, 4))\n",
        "        sns.scatterplot(x=feature, y='Yield_ton_per_hec', data=df_merged.toPandas(), alpha=0.5)\n",
        "        plt.title(f'Relationship between {feature} and Yield')\n",
        "        plt.tight_layout()\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KVxBTLTLfKVS"
      },
      "source": [
        "--------------------------------------------------------------------------------\n",
        "### 6. FINAL PROCESSED DATA SAVE\n",
        "--------------------------------------------------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HcMPVoWSfM4D"
      },
      "source": [
        "##### FINAL PROCESSED DATA SAVE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ye1JJHVqfHrR"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Select final columns to keep\n",
        "final_columns = ['State_Name', 'District_Name', 'Crop', 'Season', 'Crop_Year',\n",
        "                'Area', 'Production', 'kharif_rainfall', 'rabi_rainfall',\n",
        "                'summer_rainfall', 'yearly_rainfall', 'kharif_temp', 'rabi_temp',\n",
        "                'summer_temp', 'yearly_temp', 'N', 'P', 'K', 'pH',\n",
        "                'relevant_rainfall', 'relevant_temperature', 'rainfall_temp_interaction',\n",
        "                'NPK_ratio', 'lagged_production_1yr', 'lagged_yield_1yr',\n",
        "                'Yield_ton_per_hec']\n",
        "\n",
        "df_final = df_merged.select(final_columns)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BloDXAVxgAlj"
      },
      "outputs": [],
      "source": [
        "df_final.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HnKVSqsOf_Yc"
      },
      "outputs": [],
      "source": [
        "# Save final processed data\n",
        "df_final.toPandas().to_csv('agripredict_final_processed_data.csv', index=False)\n",
        "print(\"    - Final processed data saved to 'agripredict_final_processed_data.csv'\")\n",
        "\n",
        "print(\"\\n=== PROCESSING COMPLETE ===\")\n",
        "df_final.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}